{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(Path('Resources/2019loans.csv'))\n",
    "test_df = pd.read_csv(Path('Resources/2020Q1loans.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical data to numeric and separate target feature for training data\n",
    "X = train_df.drop('loan_status', axis =1)\n",
    "X\n",
    "\n",
    "X_train = pd.get_dummies(X)\n",
    "print(X_train.columns)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertion output labels to 0 and 1\n",
    "y_label = LabelEncoder().fit_transform(train_df['loan_status'])\n",
    "y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df['loan_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical data to numeric and separate target feature for testing data\n",
    "X = test_df.drop('loan_status', axis =1)\n",
    "X\n",
    "\n",
    "X_train = pd.get_dummies(X)\n",
    "print(X_train.columns)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertion output labels to 0 and 1\n",
    "y_label = LabelEncoder().fit_transform(test_df['loan_status'])\n",
    "y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_df['loan_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add missing dummy variables to testing set\n",
    "# Get missing columns in the training test\n",
    "missing_cols = set( train_df.columns ) - set( test_df.columns )\n",
    "# Add a missing column in test set with default value equal to 0\n",
    "for c in missing_cols:\n",
    "    test[c] = 0\n",
    "# Ensure the order of column in the test set is in the same order than in train set\n",
    "test = test_df[train_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use SelectFromModel to only get the important features\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# create selection object by passing in the model fitted above\n",
    "# Note, the original model MUST be one that has a feature_importances_ or coef_\n",
    "sel = SelectFromModel(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Logistic Regression model on the unscaled data and print the model score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the Selectedfeatured scaled data to logisticRegression and\n",
    "RandomForestRegression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest Classifier model and print the model score\n",
    "clf = RandomForestClassifier(random_state=1, n_estimators=500).fit(X_selected_train_scaled, y_train)\n",
    "print(f'Training Score: {clf.score(X_train_scaled, y_train)}')\n",
    "print(f'Testing Score: {clf.score(X_test_scaled, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the selected feature scales data \n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_selected_train_scaled, y_train)\n",
    "print(f'Training Score: {clf.score(X_train_scaled, y_train)}')\n",
    "print(f'Testing Score: {clf.score(X_test_scaled, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale  feature selected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = StandardScaler().fit(X_selected_train)\n",
    "X_selected_train_scaled = scaler.transform(X_selected_train)\n",
    "X_selected_test_scaled = scaler.transform(X_selected_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A guess on logisticRegression vs. RandomForestRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF still seems to be the better modelto use on the variability of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Logistic Regression model on the scaled data and print the model score\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_selected_train_scaled, y_train)\n",
    "print(f'Training Score: {clf.score(X_train_scaled, y_train)}')\n",
    "print(f'Testing Score: {clf.score(X_test_scaled, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest Classifier model on the scaled data and print the model score\n",
    "clf = RandomForestClassifier(random_state=1, n_estimators=500).fit(X_selected_train_scaled, y_train)\n",
    "print(f'Training Score: {clf.score(X_train_scaled, y_train)}')\n",
    "print(f'Testing Score: {clf.score(X_test_scaled, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression model fit to the full dataset is overfitting the training data. That is, the  noisy parameters confuse it. However, fitting to the smaller dataset with the selected\n",
    "features has less noisy parameters to confuse the model. So we get a more accurate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypertuning feature selected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN Classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the grid search estimator along with a parameter object containing the values to adjust\n",
    "# Try adjusting n_neighbors with values of 1 to 19\n",
    "# Include both uniform and distance option for weights.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "        'n_neighbors':[1,3,5,7,9,11,13,15,17,19],\n",
    "        'weights': ['uniform','distance'];\n",
    "        'leaf_size':[10,50,100,500]\n",
    "}\n",
    "grid_clf = GridSearchCV(model, param_ grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the SVC model\n",
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C':[1,5,10,50],\n",
    "             'kernel':('linear','rbf','signoid')}\n",
    "param_grid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonAdv]",
   "language": "python",
   "name": "conda-env-PythonAdv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
